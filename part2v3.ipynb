{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "part2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/akamojo/PAD-project/blob/master/part2v3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zx9U5s-q36iQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "outputId": "b38c1073-ae33-4668-a029-efcf28c9a3ed"
      },
      "source": [
        "!pip install --force https://github.com/chengs/tqdm/archive/colab.zip"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting https://github.com/chengs/tqdm/archive/colab.zip\n",
            "\u001b[?25l  Downloading https://github.com/chengs/tqdm/archive/colab.zip\n",
            "\u001b[K     | 604kB 3.4MB/s\n",
            "\u001b[?25hBuilding wheels for collected packages: tqdm\n",
            "  Building wheel for tqdm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-fn9uchxd/wheels/41/18/ee/d5dd158441b27965855b1bbae03fa2d8a91fe645c01b419896\n",
            "Successfully built tqdm\n",
            "Installing collected packages: tqdm\n",
            "  Found existing installation: tqdm 4.28.1\n",
            "    Uninstalling tqdm-4.28.1:\n",
            "      Successfully uninstalled tqdm-4.28.1\n",
            "Successfully installed tqdm-4.28.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FfGi6IV3wHcr",
        "colab": {}
      },
      "source": [
        "import re\n",
        "from tqdm import tqdm_notebook as tqdm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rffrtUAUwJR-",
        "outputId": "3774790d-74a1-4365-e5e8-a6c2886b20ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "17-cUaXGwHc1",
        "colab": {}
      },
      "source": [
        "file = open(\"/content/drive/My Drive/STUDIA/SEM 8/pad/en1.8m.txt\", \"r\", encoding=\"utf8\")\n",
        "#file = open(\"en1.8m.txt\", \"r\", encoding=\"utf8\")\n",
        "\n",
        "whole_text = file.read()\n",
        "text = whole_text.split('\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9PHsE2zqwHdE",
        "colab": {}
      },
      "source": [
        "def append_space(text, pattern, left=True):\n",
        "    p = re.compile(\"[\" + pattern + \"]\")\n",
        "    \n",
        "    for i, m in enumerate(p.finditer(text)):\n",
        "        if left:\n",
        "            text = text[: m.start() + i] + \" \" + text[m.start() + i :]\n",
        "        else:\n",
        "            text = text[: m.start() + 1 + i] + \" \" + text[m.start() + 1 + i :]\n",
        "            \n",
        "    return text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0oVrjurXwHdQ",
        "colab": {}
      },
      "source": [
        "def preprocessing(text):\n",
        "    for i in range(len(text)):\n",
        "        text[i] = append_space(text[i], \",\\])>\")\n",
        "        text[i] = append_space(text[i], \".\")\n",
        "        text[i] = append_space(text[i], \"\\[(<\", False)\n",
        "      \n",
        "    return text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9x-KrFiNwHdU",
        "colab": {}
      },
      "source": [
        "def build_n_gram(text_arr, n_gram, grams):\n",
        "    cur_gram = []\n",
        "    count_gram = 0\n",
        "\n",
        "    for i in range(len(text_arr)):\n",
        "\n",
        "        cur_gram = [text_arr[i]]\n",
        "\n",
        "        for j in range(i + 1, i + n_gram):\n",
        "            if j < len(text_arr):\n",
        "                cur_gram.append(text_arr[j])\n",
        "\n",
        "        if len(cur_gram) == n_gram:\n",
        "            try:\n",
        "                grams[\" \".join(cur_gram)] += 1\n",
        "            except KeyError:\n",
        "                grams[\" \".join(cur_gram)] = 1\n",
        "\n",
        "    return grams"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pkr_cvxVwHdd",
        "colab": {}
      },
      "source": [
        "def build_dict(text, n_s):\n",
        "    dictionary = []\n",
        "    for n in range(n_s):\n",
        "        dictionary.append(dict())\n",
        "    \n",
        "    for n in range(n_s):\n",
        "        for line in text:\n",
        "            dictionary[n] = build_n_gram(line.split(), n + 1, dictionary[n])\n",
        "        \n",
        "    return dictionary"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UZrO6W8pwHdg",
        "colab": {}
      },
      "source": [
        "def SCP_f(words, dictionary):\n",
        "    words_arr = words.split()\n",
        "    \n",
        "    numerator = dictionary[len(words_arr) - 1][words] ** 2\n",
        "    F = 1 / (len(words_arr) - 1)\n",
        "    denominator = 0\n",
        "    \n",
        "    for i in range(len(words_arr) - 1):\n",
        "        left = words_arr[0:i+1]\n",
        "        right = words_arr[i+1:]\n",
        "        \n",
        "        denominator += dictionary[len(left) - 1][\" \".join(left)] * dictionary[len(right) - 1][\" \".join(right)]\n",
        "        \n",
        "    F *= denominator\n",
        "    return numerator / F"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bs4Uhmut6fSt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def dice(words, dictionary):\n",
        "    words_arr = words.split()\n",
        "    \n",
        "    numerator = dictionary[len(words_arr) - 1][words] * 2\n",
        "    F = 1 / (len(words_arr) - 1)\n",
        "    denominator = 0\n",
        "    \n",
        "    for i in range(len(words_arr) - 1):\n",
        "        left = words_arr[0:i+1]\n",
        "        right = words_arr[i+1:]\n",
        "        \n",
        "        denominator += dictionary[len(left) - 1][\" \".join(left)] + dictionary[len(right) - 1][\" \".join(right)]\n",
        "        \n",
        "    F *= denominator\n",
        "    return numerator / F"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QFt8PTVOESoI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def LocalMax(text, table):\n",
        "    xys = dict()\n",
        "    \n",
        "    for nr in tqdm(range(len(text))):\n",
        "        line = text[nr]\n",
        "\n",
        "        text_arr = line.split()\n",
        "\n",
        "        if len(text_arr) < 2:\n",
        "            continue\n",
        "\n",
        "        for i in range(len(text_arr) - 2):\n",
        "            cur_gram = \" \".join(text_arr[i:i+2])\n",
        "\n",
        "            j = i + 3\n",
        "            n_gram = 1\n",
        "\n",
        "            while j < len(text_arr) and n_gram < 6:\n",
        "                next_gram = \" \".join(text_arr[i:j])\n",
        "\n",
        "                try:\n",
        "                    xys[cur_gram][1] = max(xys[cur_gram][1], table[next_gram])\n",
        "                    \n",
        "                except KeyError:\n",
        "                    if len(cur_gram.split()) > 2:\n",
        "                        x = table[\" \".join(cur_gram.split()[:-1])]\n",
        "                        x = max(x, table[\" \".join(cur_gram.split()[1:])])\n",
        "                        xys[cur_gram] = [x, table[next_gram]]\n",
        "                    else:\n",
        "                        xys[cur_gram] = [-1, table[next_gram]]\n",
        "\n",
        "                cur_gram = next_gram\n",
        "\n",
        "                j += 1\n",
        "                n_gram += 1\n",
        "\n",
        "            cur_gram = \" \".join(text_arr[i:i+2])\n",
        "            j = i - 1\n",
        "            n_gram = 1\n",
        "\n",
        "            while j >= 0 and n_gram < 6:\n",
        "                next_gram = \" \".join(text_arr[j:i+2])\n",
        "\n",
        "\n",
        "                try:                        \n",
        "                    xys[cur_gram][1] = max(xys[cur_gram][1], table[next_gram])\n",
        "                    \n",
        "                except KeyError:\n",
        "                    if len(cur_gram.split()) > 2:\n",
        "                        x = table[\" \".join(cur_gram.split()[:-1])]\n",
        "                        x = max(x, table[\" \".join(cur_gram.split()[1:])])\n",
        "                        xys[cur_gram] = [x, table[next_gram]]\n",
        "                    else:\n",
        "                        xys[cur_gram] = [-1, table[next_gram]]\n",
        "\n",
        "\n",
        "                cur_gram = next_gram\n",
        "\n",
        "                j -= 1\n",
        "                n_gram += 1\n",
        "              \n",
        "    return xys"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0wd9fUsowHdq",
        "colab": {}
      },
      "source": [
        "def main(text, max_gram, threshold, glue_fun):\n",
        "    print(\"Preprocessing text\")\n",
        "    text = preprocessing(text)\n",
        "    \n",
        "    print(\"Building dictionary with frequencies\")\n",
        "\n",
        "    dictionary = build_dict(text, max_gram)\n",
        "    \n",
        "    table = dict()\n",
        "        \n",
        "    print(\"Proceeding to calculating glue value\")\n",
        "    print(\"Glue value calculated for:\")\n",
        "\n",
        "    for i in range(2, max_gram + 1):\n",
        "        print(i, \"grams\")\n",
        "        for s in dictionary[i - 1]:\n",
        "          table[s] = glue_fun(s, dictionary) #dice(s, dictionary)\n",
        "    \n",
        "    print(\"Proceeding to Localmax\")\n",
        "    \n",
        "    RE = []\n",
        "    xys = LocalMax(text, table)\n",
        "            \n",
        "    for g in xys:\n",
        "        if xys[g][0] == -1:\n",
        "            xys[g][0] = xys[g][1]\n",
        "        \n",
        "        val = (xys[g][0] + xys[g][1]) / 2\n",
        "        \n",
        "        if table[g] > val and re.match(r\"^[a-z\\'A-Z\\s]*$\", g) and dictionary[len(g.split()) - 1][g] > threshold:\n",
        "            RE.append(g)\n",
        "    \n",
        "    return RE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0MGuj-XKEl89",
        "colab_type": "code",
        "outputId": "fa33a404-07f5-4897-b109-e4e2c3765eb8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        }
      },
      "source": [
        "test = whole_text.split('\\n')[0]\n",
        "\n",
        "RE = main([test], 7, 1, SCP_f)\n",
        "print(\"Obtained\", len(RE), \"Relevant Expressions\")\n",
        "RE"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Preprocessing text\n",
            "[\"Greek Christian scribes played a crucial role in the preservation of Aristotle by copying all the extant Greek language manuscripts of the corpus . The first Greek Christians to comment extensively on Aristotle were John Philoponus , Elias , and David in the sixth century , and Stephen of Alexandria in the early seventh century . John Philoponus stands out for having attempted a fundamental critique of Aristotle's views on the eternity of the world , movement , and other elements of Aristotelian thought . After a hiatus of several centuries , formal commentary by Eustratius and Michael of Ephesus reappears in the late eleventh and early twelfth centuries , apparently sponsored by Anna Comnena .\"]\n",
            "Building dictionary with frequencies\n",
            "Proceeding to calculating glue value\n",
            "Glue value calculated for:\n",
            "2 grams\n",
            "3 grams\n",
            "4 grams\n",
            "5 grams\n",
            "6 grams\n",
            "7 grams\n",
            "Proceeding to Localmax\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span></span><progress style='margin:2px 4px;' max='1' value='1'></progress>100% 1/1 [00:00&lt;00:00, 80.20it/s]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Obtained 2 Relevant Expressions\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['in the', 'John Philoponus']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PtcH06Du7TeP",
        "colab_type": "code",
        "outputId": "3aec8697-e2b5-4532-ab66-855186c999f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        }
      },
      "source": [
        "RE = main(text, 7, 1, SCP_f)\n",
        "print(\"Obtained\", len(RE), \"Relevant Expressions\")"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Building dictionary with frequencies\n",
            "Proceeding to calculating glue value\n",
            "Glue value calculated for:\n",
            "2 grams\n",
            "3 grams\n",
            "4 grams\n",
            "5 grams\n",
            "6 grams\n",
            "7 grams\n",
            "Proceeding to Localmax\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span></span><progress style='margin:2px 4px;' max='69468' value='69468'></progress>100% 69468/69468 [00:52&lt;00:00, 1330.38it/s]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Obtained 19059 Relevant Expressions\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wLzfnTVJI1rG",
        "colab_type": "code",
        "outputId": "b2a176c4-578b-45a4-b958-f31f1c5b339a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        }
      },
      "source": [
        "RE = main(text, 7, 1, dice)\n",
        "print(\"Obtained\", len(RE), \"Relevant Expressions\")"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Preprocessing text\n",
            "Building dictionary with frequencies\n",
            "Proceeding to calculating glue value\n",
            "Glue value calculated for:\n",
            "2 grams\n",
            "3 grams\n",
            "4 grams\n",
            "5 grams\n",
            "6 grams\n",
            "7 grams\n",
            "Proceeding to Localmax\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span></span><progress style='margin:2px 4px;' max='69468' value='69468'></progress>100% 69468/69468 [00:51&lt;00:00, 1347.27it/s]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Obtained 38124 Relevant Expressions\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LNynzPSz5tYI",
        "colab_type": "code",
        "outputId": "0569060f-6a0c-468d-b45c-d67712efe78b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1751
        }
      },
      "source": [
        "RE[:100]"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['crucial role',\n",
              " 'in the',\n",
              " 'manuscripts of',\n",
              " 'of the',\n",
              " 'The first',\n",
              " 'John Philoponus',\n",
              " 'out for',\n",
              " 'on the',\n",
              " 'and other',\n",
              " 'other elements',\n",
              " 'several centuries',\n",
              " 'communications equipment',\n",
              " 'based on',\n",
              " 'The wording',\n",
              " 'with the',\n",
              " 'divided into',\n",
              " 'or gross',\n",
              " 'is the',\n",
              " 'of an',\n",
              " 'body parts',\n",
              " 'also includes',\n",
              " 'use of',\n",
              " 'known as',\n",
              " 'and also',\n",
              " 'also in',\n",
              " 'what is now',\n",
              " 'from the',\n",
              " 'to the',\n",
              " 'lived there',\n",
              " 'as a',\n",
              " 'was not',\n",
              " 'before the end',\n",
              " 'by the',\n",
              " 'only by',\n",
              " 'After independence',\n",
              " 'civil war',\n",
              " 'areas such',\n",
              " 'such as',\n",
              " 'which have',\n",
              " 'have included',\n",
              " 'included the former',\n",
              " 'dawn of',\n",
              " 'establishment of the Ottoman',\n",
              " 'Ottoman Empire',\n",
              " 'The Ottomans',\n",
              " 'over most',\n",
              " 'many times',\n",
              " 'led by',\n",
              " 'and later',\n",
              " 'later established',\n",
              " 'He also',\n",
              " 'which they',\n",
              " 'for the',\n",
              " 'western Europe',\n",
              " 'as well',\n",
              " 'as well as',\n",
              " 'in the form of',\n",
              " 'is a',\n",
              " 'Indic scripts',\n",
              " 'Southeast Asia',\n",
              " 'Today they',\n",
              " 'they are',\n",
              " 'are used',\n",
              " 'used in',\n",
              " 'South Asia',\n",
              " 'some other',\n",
              " 'mainland Southeast',\n",
              " 'but not',\n",
              " 'The primary',\n",
              " 'Northern India',\n",
              " 'South India',\n",
              " 'Sri Lanka',\n",
              " 'near the site',\n",
              " 'in which',\n",
              " 'which the',\n",
              " 'army led',\n",
              " 'King Henry',\n",
              " 'defeated the forces',\n",
              " 'forces led',\n",
              " 'Charles VI',\n",
              " 'Charles VI of France',\n",
              " 'VI of France',\n",
              " 'which has',\n",
              " 'gone down',\n",
              " 'as the',\n",
              " 'According to',\n",
              " 'by their',\n",
              " 'that they',\n",
              " 'they were',\n",
              " 'even before',\n",
              " 'before the start',\n",
              " 'the start of the',\n",
              " 'start of the battle',\n",
              " 'was a',\n",
              " 'that could',\n",
              " 'but which',\n",
              " 'them to',\n",
              " 'to be',\n",
              " 'he found',\n",
              " 'it only']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-YJHSl4wGNk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "file = open(\"/content/drive/My Drive/STUDIA/SEM 8/pad/en3.67m.txt\", \"r\", encoding=\"utf8\")\n",
        "\n",
        "whole_text = file.read()\n",
        "text = whole_text.split('\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YPkeds0p6G3l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        },
        "outputId": "4891917e-3be4-4539-afc4-75944c993451"
      },
      "source": [
        "RE = main(text, 7, 1, SCP_f)\n",
        "print(\"Obtained\", len(RE), \"Relevant Expressions\")"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Preprocessing text\n",
            "Building dictionary with frequencies\n",
            "Proceeding to calculating glue value\n",
            "Glue value calculated for:\n",
            "2 grams\n",
            "3 grams\n",
            "4 grams\n",
            "5 grams\n",
            "6 grams\n",
            "7 grams\n",
            "Proceeding to Localmax\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span></span><progress style='margin:2px 4px;' max='138936' value='138936'></progress>100% 138936/138936 [01:48&lt;00:00, 1276.31it/s]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Obtained 38351 Relevant Expressions\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q9EoOP-YyISe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1751
        },
        "outputId": "0e770977-565d-4ac4-8dfd-ea6d92af5994"
      },
      "source": [
        "RE[:100]"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['alcoholic beverage',\n",
              " 'that the',\n",
              " 'on the',\n",
              " 'the sale of',\n",
              " 'alcoholic beverages',\n",
              " 'in the',\n",
              " 'of the',\n",
              " 'there are',\n",
              " 'crucial role',\n",
              " 'The first',\n",
              " 'John Philoponus',\n",
              " 'and other',\n",
              " 'part of',\n",
              " 'in the northern part of',\n",
              " 'northern part',\n",
              " 'where it',\n",
              " 'as much as',\n",
              " 'communications equipment',\n",
              " 'based on',\n",
              " 'The assumption',\n",
              " 'the same',\n",
              " 'with the',\n",
              " 'with a',\n",
              " 'with an',\n",
              " 'an apogee',\n",
              " 'and a',\n",
              " 'to the',\n",
              " 'orbital period',\n",
              " 'divided into',\n",
              " 'of an',\n",
              " 'the use of',\n",
              " 'the study of',\n",
              " 'known as',\n",
              " 'according to',\n",
              " 'the second',\n",
              " 'in terms of',\n",
              " 'what is now',\n",
              " 'from the',\n",
              " 'began to',\n",
              " 'as a',\n",
              " 'was not',\n",
              " 'end of',\n",
              " 'by the',\n",
              " 'after the',\n",
              " 'of their',\n",
              " 'civil war',\n",
              " 'such as',\n",
              " 'decreasing order',\n",
              " 'most common',\n",
              " 'for the',\n",
              " 'number of',\n",
              " 'and the',\n",
              " 'the dawn of',\n",
              " 'the establishment of',\n",
              " 'Ottoman Empire',\n",
              " 'Southeast Europe',\n",
              " 'most of',\n",
              " 'led by',\n",
              " 'He also',\n",
              " 'which they',\n",
              " 'as well as',\n",
              " 'in the form of',\n",
              " 'his father',\n",
              " 'In the same year',\n",
              " 'same year',\n",
              " 'at the',\n",
              " 'After leaving',\n",
              " 'he became',\n",
              " 'became a',\n",
              " 'During the First World',\n",
              " 'During the First World War',\n",
              " 'military service',\n",
              " 'because of',\n",
              " 'of his',\n",
              " 'have been',\n",
              " 'by a',\n",
              " 'young man',\n",
              " 'up to',\n",
              " 'to a',\n",
              " 'which he',\n",
              " 'is a',\n",
              " 'have a',\n",
              " 'more than',\n",
              " 'a few',\n",
              " 'Indic scripts',\n",
              " 'Southeast Asia',\n",
              " 'they are',\n",
              " 'used in',\n",
              " 'replaced by',\n",
              " 'but not',\n",
              " 'Sri Lanka',\n",
              " 'the beginning of',\n",
              " 'moved to',\n",
              " 'to become',\n",
              " 'the site of',\n",
              " 'Charles VI',\n",
              " 'Charles VI of France',\n",
              " 'which has',\n",
              " 'as the',\n",
              " 'According to']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    }
  ]
}